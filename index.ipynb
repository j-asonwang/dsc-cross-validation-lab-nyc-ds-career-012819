{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Cross-Validation - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll be able to practice your cross-validation skills!\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Compare the results with normal holdout validation\n",
    "- Apply 5-fold cross validation for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started\n",
    "\n",
    "This time, let's only include the variables that were previously selected using recursive feature elimination. We included the code to preprocess below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "boston_features = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "b = boston_features[\"B\"]\n",
    "logdis = np.log(boston_features[\"DIS\"])\n",
    "loglstat = np.log(boston_features[\"LSTAT\"])\n",
    "\n",
    "# minmax scaling\n",
    "boston_features[\"B\"] = (b-min(b))/(max(b)-min(b))\n",
    "boston_features[\"DIS\"] = (logdis-min(logdis))/(max(logdis)-min(logdis))\n",
    "\n",
    "#standardization\n",
    "boston_features[\"LSTAT\"] = (loglstat-np.mean(loglstat))/np.sqrt(np.var(loglstat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = boston_features[['CHAS', 'RM', 'DIS', 'B', 'LSTAT']]\n",
    "y = pd.DataFrame(boston.target,columns = ['target'])\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split\n",
    "\n",
    "Perform a train-test-split with a test set of 0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[     CHAS     RM       DIS         B     LSTAT\n",
       " 381   0.0  6.545  0.124844  1.000000  1.128374\n",
       " 283   1.0  7.923  0.695396  0.996520 -2.032981\n",
       " 68    0.0  5.594  0.737143  1.000000  0.334640\n",
       " 205   0.0  5.891  0.526931  1.000000  0.025057\n",
       " 338   0.0  6.059  0.610606  0.998084 -0.382682\n",
       " 359   0.0  6.112  0.336234  0.984467  0.280314\n",
       " 88    0.0  7.007  0.466931  1.000000 -1.109812\n",
       " 236   1.0  6.631  0.548029  0.978693 -0.192357\n",
       " 491   0.0  5.983  0.211945  0.982879  0.871715\n",
       " 328   0.0  5.868  0.644441  0.963538 -0.118915\n",
       " 93    0.0  6.211  0.495975  0.998563 -0.907557\n",
       " 154   1.0  6.129  0.184286  0.808664  0.574804\n",
       " 315   0.0  5.705  0.526888  0.998790  0.118911\n",
       " 253   0.0  8.259  0.869987  1.000000 -1.843817\n",
       " 6     0.0  6.012  0.671500  0.996722  0.248456\n",
       " 274   1.0  6.758  0.540817  1.000000 -1.848530\n",
       " 85    0.0  6.630  0.576472  0.988401 -0.823856\n",
       " 227   0.0  7.163  0.440770  0.937415 -0.867798\n",
       " 420   0.0  6.411  0.209865  0.802940  0.563750\n",
       " 229   0.0  6.552  0.461153  0.958243 -1.743380\n",
       " 459   0.0  6.081  0.369850  1.000000  0.527876\n",
       " 493   0.0  5.707  0.314279  1.000000  0.191196\n",
       " 228   0.0  7.686  0.461153  0.951107 -1.673960\n",
       " 119   0.0  5.731  0.376265  0.986384  0.399535\n",
       " 411   0.0  6.657  0.127139  0.087574  1.139400\n",
       " 187   0.0  6.782  0.509845  0.992360 -0.786023\n",
       " 267   0.0  8.297  0.321279  0.968834 -0.606523\n",
       " 370   1.0  7.016  0.026314  0.987770 -2.141899\n",
       " 191   0.0  6.739  0.735961  0.981870 -1.375206\n",
       " 490   0.0  5.093  0.201557  0.802133  1.698339\n",
       " ..    ...    ...       ...       ...       ...\n",
       " 445   0.0  6.459  0.238133  0.107771  1.343093\n",
       " 44    0.0  6.069  0.683481  0.981063 -0.190612\n",
       " 262   0.0  8.398  0.297461  0.974684 -0.990042\n",
       " 215   0.0  6.182  0.526931  0.991755 -0.204626\n",
       " 421   0.0  6.006  0.213409  0.806042  0.637510\n",
       " 134   0.0  5.757  0.307916  0.661758  0.800136\n",
       " 383   0.0  5.520  0.128681  1.000000  1.382905\n",
       " 372   1.0  5.875  0.000000  0.876393 -0.311785\n",
       " 30    0.0  5.713  0.556575  0.907383  1.244358\n",
       " 336   0.0  5.869  0.645772  1.000000 -0.147565\n",
       " 70    0.0  6.417  0.650274  0.966791 -0.776077\n",
       " 9     0.0  6.004  0.743201  0.974305  0.779802\n",
       " 402   0.0  6.404  0.156822  0.947577  1.066385\n",
       " 33    0.0  5.701  0.509690  0.903853  0.897329\n",
       " 156   0.0  5.272  0.181144  0.222679  0.683554\n",
       " 362   0.0  5.362  0.261967  0.959378 -0.082556\n",
       " 343   0.0  6.696  0.684305  1.000000 -0.665780\n",
       " 440   0.0  5.818  0.211517  0.986258  1.207843\n",
       " 196   0.0  7.287  0.786695  1.000000 -1.607317\n",
       " 78    0.0  6.232  0.627922  0.973524  0.236351\n",
       " 80    0.0  6.727  0.659214  1.000000 -1.174663\n",
       " 358   1.0  6.127  0.370655  0.996293  0.116011\n",
       " 128   0.0  6.431  0.199215  1.000000  0.604289\n",
       " 346   0.0  5.898  0.825470  0.918579  0.280314\n",
       " 188   0.0  6.556  0.588544  0.964547 -1.422033\n",
       " 270   0.0  5.856  0.575645  0.979197  0.323147\n",
       " 86    0.0  6.015  0.575474  0.997705  0.305110\n",
       " 75    0.0  6.286  0.582589  0.965530 -0.300567\n",
       " 189   0.0  7.185  0.588544  1.000000 -1.143466\n",
       " 167   0.0  5.877  0.322026  0.573125  0.209131\n",
       " \n",
       " [404 rows x 5 columns],      CHAS     RM       DIS         B     LSTAT\n",
       " 81    0.0  6.619  0.659214  0.996798 -0.656525\n",
       " 110   0.0  6.195  0.379096  0.991401  0.323147\n",
       " 87    0.0  6.121  0.505261  0.995587 -0.396442\n",
       " 163   1.0  8.375  0.273504  0.978693 -1.950701\n",
       " 37    0.0  5.850  0.525733  1.000000 -0.332549\n",
       " 276   1.0  7.267  0.608411  0.980710 -0.951040\n",
       " 444   0.0  5.854  0.218102  0.605679  1.329841\n",
       " 72    0.0  6.065  0.650274  0.984896 -1.103765\n",
       " 309   0.0  5.972  0.425672  0.998336 -0.118915\n",
       " 77    0.0  6.140  0.542148  0.974936 -0.069529\n",
       " 152   1.0  5.012  0.149353  0.864794  0.206384\n",
       " 46    0.0  5.786  0.635111  1.000000  0.464352\n",
       " 265   0.0  5.560  0.237836  0.988653 -0.040585\n",
       " 47    0.0  6.030  0.681155  0.989510  0.937688\n",
       " 319   0.0  6.113  0.532922  0.998311  0.288184\n",
       " 31    0.0  6.072  0.550762  0.949140  0.328265\n",
       " 28    0.0  6.495  0.578083  0.977407  0.297319\n",
       " 390   0.0  5.713  0.224915  0.993772  0.780776\n",
       " 64    0.0  7.104  0.884685  0.990771 -0.475253\n",
       " 105   0.0  5.851  0.262627  0.992814  0.717270\n",
       " 277   1.0  6.826  0.615013  0.991301 -1.574970\n",
       " 136   0.0  5.942  0.233658  0.952973  0.760204\n",
       " 181   0.0  6.144  0.350887  1.000000 -0.208148\n",
       " 4     0.0  7.147  0.707895  1.000000 -1.162114\n",
       " 460   0.0  6.701  0.350822  0.642771  0.712205\n",
       " 289   0.0  6.565  0.787167  0.936507 -0.197604\n",
       " 192   0.0  7.178  0.735961  0.983837 -2.193335\n",
       " 377   0.0  6.794  0.077585  1.000000  1.140970\n",
       " 142   1.0  5.403  0.066138  1.000000  1.529547\n",
       " 320   0.0  6.426  0.586111  1.000000 -0.661146\n",
       " ..    ...    ...       ...       ...       ...\n",
       " 480   0.0  6.242  0.467238  1.000000  0.005014\n",
       " 240   0.0  6.897  0.726513  0.985753  0.101437\n",
       " 435   0.0  6.629  0.266172  0.276186  1.293026\n",
       " 182   0.0  7.155  0.367221  0.992990 -1.329660\n",
       " 258   0.0  7.333  0.217880  0.965682 -0.529945\n",
       " 465   0.0  5.759  0.420755  0.842403  0.461996\n",
       " 193   0.0  6.800  0.718694  0.991099 -1.258618\n",
       " 62    0.0  6.456  0.781854  1.000000 -0.773600\n",
       " 138   0.0  5.857  0.164363  0.987745  1.147232\n",
       " 0     0.0  6.575  0.542096  1.000000 -1.275260\n",
       " 431   0.0  6.833  0.258871  0.204272  1.014740\n",
       " 56    0.0  6.383  0.883069  1.000000 -1.029978\n",
       " 323   0.0  5.708  0.602553  0.985451  0.153318\n",
       " 55    0.0  7.249  0.859930  0.997554 -1.333120\n",
       " 150   0.0  6.122  0.151389  0.939230  0.458456\n",
       " 161   0.0  7.489  0.234514  0.943341 -3.036568\n",
       " 206   0.0  6.326  0.568536  0.994881  0.040312\n",
       " 194   0.0  6.604  0.718694  0.949065 -1.489123\n",
       " 173   0.0  6.416  0.358664  0.996470 -0.282037\n",
       " 401   0.0  6.343  0.139800  1.000000  1.067205\n",
       " 16    0.0  5.935  0.582214  0.974658 -0.811149\n",
       " 432   0.0  6.425  0.280922  0.246180  0.193968\n",
       " 419   0.0  6.824  0.194893  0.121363  1.254646\n",
       " 482   0.0  7.061  0.465562  0.995915 -0.705696\n",
       " 386   0.0  4.652  0.110170  1.000000  1.617848\n",
       " 502   0.0  6.120  0.297277  1.000000 -0.274682\n",
       " 53    0.0  5.998  0.757192  1.000000 -0.398417\n",
       " 13    0.0  5.949  0.601338  1.000000 -0.432353\n",
       " 256   0.0  7.454  0.726513  0.973372 -2.059550\n",
       " 410   0.0  5.757  0.094312  0.005749 -0.095686\n",
       " \n",
       " [102 rows x 5 columns],      target\n",
       " 381    10.9\n",
       " 283    50.0\n",
       " 68     17.4\n",
       " 205    22.6\n",
       " 338    20.6\n",
       " 359    22.6\n",
       " 88     23.6\n",
       " 236    25.1\n",
       " 491    13.6\n",
       " 328    19.3\n",
       " 93     25.0\n",
       " 154    17.0\n",
       " 315    16.2\n",
       " 253    42.8\n",
       " 6      22.9\n",
       " 274    32.4\n",
       " 85     26.6\n",
       " 227    31.6\n",
       " 420    16.7\n",
       " 229    31.5\n",
       " 459    20.0\n",
       " 493    21.8\n",
       " 228    46.7\n",
       " 119    19.3\n",
       " 411    17.2\n",
       " 187    32.0\n",
       " 267    50.0\n",
       " 370    50.0\n",
       " 191    30.5\n",
       " 490     8.1\n",
       " ..      ...\n",
       " 445    11.8\n",
       " 44     21.2\n",
       " 262    48.8\n",
       " 215    25.0\n",
       " 421    14.2\n",
       " 134    15.6\n",
       " 383    12.3\n",
       " 372    50.0\n",
       " 30     12.7\n",
       " 336    19.5\n",
       " 70     24.2\n",
       " 9      18.9\n",
       " 402    12.1\n",
       " 33     13.1\n",
       " 156    13.1\n",
       " 362    20.8\n",
       " 343    23.9\n",
       " 440    10.5\n",
       " 196    33.3\n",
       " 78     21.2\n",
       " 80     28.0\n",
       " 358    22.7\n",
       " 128    18.0\n",
       " 346    17.2\n",
       " 188    29.8\n",
       " 270    21.1\n",
       " 86     22.5\n",
       " 75     21.4\n",
       " 189    34.9\n",
       " 167    23.8\n",
       " \n",
       " [404 rows x 1 columns],      target\n",
       " 81     23.9\n",
       " 110    21.7\n",
       " 87     22.2\n",
       " 163    50.0\n",
       " 37     21.0\n",
       " 276    33.2\n",
       " 444    10.8\n",
       " 72     22.8\n",
       " 309    20.3\n",
       " 77     20.8\n",
       " 152    15.3\n",
       " 46     20.0\n",
       " 265    22.8\n",
       " 47     16.6\n",
       " 319    21.0\n",
       " 31     14.5\n",
       " 28     18.4\n",
       " 390    15.1\n",
       " 64     33.0\n",
       " 105    19.5\n",
       " 277    33.1\n",
       " 136    17.4\n",
       " 181    36.2\n",
       " 4      36.2\n",
       " 460    16.4\n",
       " 289    24.8\n",
       " 192    36.4\n",
       " 377    13.3\n",
       " 142    13.4\n",
       " 320    23.8\n",
       " ..      ...\n",
       " 480    23.0\n",
       " 240    22.0\n",
       " 435    13.4\n",
       " 182    37.9\n",
       " 258    36.0\n",
       " 465    19.9\n",
       " 193    31.1\n",
       " 62     22.2\n",
       " 138    13.3\n",
       " 0      24.0\n",
       " 431    14.1\n",
       " 56     24.7\n",
       " 323    18.5\n",
       " 55     35.4\n",
       " 150    21.5\n",
       " 161    50.0\n",
       " 206    24.4\n",
       " 194    29.1\n",
       " 173    23.6\n",
       " 401     7.2\n",
       " 16     23.1\n",
       " 432    16.1\n",
       " 419     8.4\n",
       " 482    25.0\n",
       " 386    10.5\n",
       " 502    20.6\n",
       " 53     23.4\n",
       " 13     20.4\n",
       " 256    44.0\n",
       " 410    15.0\n",
       " \n",
       " [102 rows x 1 columns]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and apply the model to the make test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the residuals and the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation: let's build it from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cross-validation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function k-folds that splits a dataset into k evenly sized pieces.\n",
    "If the full dataset is not divisible by k, make the first few folds one larger then later ones.\n",
    "\n",
    "We want the folds to be a list of subsets of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds(data, k):\n",
    "    # Force data as pandas dataframe\n",
    "    # add 1 to fold size to account for leftovers           \n",
    "    return No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply it to the Boston Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to concatenate the data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a linear regression for each fold, and calculate the training and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform linear regression on each and calculate the training and test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_errs = []\n",
    "train_errs = []\n",
    "k=5\n",
    "\n",
    "for n in range(k):\n",
    "    # Split in train and test for the fold\n",
    "    train = None\n",
    "    test = None\n",
    "    # Fit a linear regression model\n",
    "    \n",
    "    #Evaluate Train and Test Errors\n",
    "\n",
    "# print(train_errs)\n",
    "# print(test_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a bit of work! Now, let's perform 5-fold cross-validation to get the mean squared error through scikit-learn. Let's have a look at the five individual MSEs and explain what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, calculate the mean of the MSE over the 5 cross-validations and compare and contrast with the result from the train-test-split case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now practiced your knowledge on k-fold crossvalidation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
